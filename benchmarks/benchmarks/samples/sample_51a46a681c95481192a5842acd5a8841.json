{
    "title": "Why was a func removed",
    "description": "",
    "id": "51a46a681c95481192a5842acd5a8841",
    "parent_id": "",
    "repo": "http://github.com/AbanteAI/mentat",
    "merge_base": "3195310a081009bc67ac7fa5e9870b3b95a12fcf",
    "diff_merge_base": "",
    "diff_active": "diff --git a/mentat/embeddings.py b/mentat/embeddings.py\nindex f6bcc4f..f4442e1 100644\n--- a/mentat/embeddings.py\n+++ b/mentat/embeddings.py\n@@ -1,2 +1 @@\n-import asyncio\n import json\n@@ -20,3 +19,3 @@ from mentat.utils import mentat_dir_path, sha256\n \n-MAX_SIMULTANEOUS_REQUESTS = 10\n+EMBEDDINGS_API_BATCH_SIZE = 2048\n \n@@ -69,31 +68,2 @@ database = EmbeddingsDatabase()\n \n-def _batch_ffd(data: dict[str, int], batch_size: int) -> list[list[str]]:\n-    \"\"\"Batch files using the First Fit Decreasing algorithm.\"\"\"\n-    # Sort the data by the length of the strings in descending order\n-    sorted_data = sorted(data.items(), key=lambda x: x[1], reverse=True)\n-    batches = list[list[str]]()\n-    for key, value in sorted_data:\n-        # Place each item in the first batch that it fits in\n-        placed = False\n-        for batch in batches:\n-            if sum(data[k] for k in batch) + value <= batch_size:\n-                batch.append(key)\n-                placed = True\n-                break\n-        if not placed:\n-            batches.append([key])\n-    return batches\n-\n-\n-embedding_api_semaphore = asyncio.Semaphore(MAX_SIMULTANEOUS_REQUESTS)\n-\n-\n-async def _fetch_embeddings(model: str, batch: list[str]):\n-    ctx = SESSION_CONTEXT.get()\n-\n-    async with embedding_api_semaphore:\n-        response = await ctx.llm_api_handler.call_embedding_api(batch, model)\n-        return response\n-\n-\n def _cosine_similarity(v1: list[float], v2: list[float]) -> float:\n@@ -117,2 +87,4 @@ async def get_feature_similarity_scores(\n     embedding_model = session_context.config.embedding_model\n+    llm_api_handler = session_context.llm_api_handler\n+\n     max_model_tokens = model_context_size(embedding_model)\n@@ -125,12 +97,12 @@ async def get_feature_similarity_scores(\n \n-    # Make a checksum:content dict of all items that need to be embedded\n-    items_to_embed = dict[str, str]()\n-    items_to_embed_tokens = dict[str, int]()\n+    # Make lists of all items that need to be embedded\n+    embed_texts = list[str]()\n+    embed_checksums = list[str]()\n+    embed_tokens = list[int]()\n     prompt_checksum = sha256(prompt)\n-    num_prompt_tokens = 0\n     if not database.exists(prompt_checksum):\n-        items_to_embed[prompt_checksum] = prompt\n-        items_to_embed_tokens[prompt_checksum] = count_tokens(\n-            prompt, embedding_model, False\n-        )\n+        prompt_tokens = count_tokens(prompt, embedding_model, False)\n+        embed_texts.append(prompt)\n+        embed_checksums.append(prompt_checksum)\n+        embed_tokens.append(prompt_tokens)\n     for feature, checksum, token in zip(features, checksums, tokens):\n@@ -140,6 +112,5 @@ async def get_feature_similarity_scores(\n             feature_content = feature.get_code_message()\n-            # Remove line numbering\n-            items_to_embed[checksum] = \"\\n\".join(feature_content)\n-            items_to_embed_tokens[checksum] = token\n-            num_prompt_tokens += token\n+            embed_texts.append(\"\\n\".join(feature_content))\n+            embed_checksums.append(checksum)\n+            embed_tokens.append(token)\n \n@@ -153,6 +124,6 @@ async def get_feature_similarity_scores(\n     else:\n-        expected_cost = (num_prompt_tokens / 1000) * cost[0]\n+        expected_cost = (sum(embed_tokens) / 1000) * cost[0]\n         if expected_cost > 1.0:\n             stream.send(\n-                f\"Embedding {num_prompt_tokens} tokens will cost ${cost[0]:.2f}.\"\n+                f\"Embedding {sum(embed_tokens)} tokens will cost ${cost[0]:.2f}.\"\n                 \" Continue anyway?\"\n@@ -164,20 +135,21 @@ async def get_feature_similarity_scores(\n     # Fetch embeddings in batches\n-    batches = _batch_ffd(items_to_embed_tokens, max_model_tokens)\n-\n-    tasks = list[tuple[asyncio.Task[list[list[float]]], list[str]]]()\n-    for batch in batches:\n-        batch_content = [items_to_embed[k] for k in batch]\n-        task = asyncio.create_task(_fetch_embeddings(embedding_model, batch_content))\n-        tasks.append((task, batch))\n-    for i, (task, batch) in enumerate(tasks):\n+    n_batches = len(embed_texts) // EMBEDDINGS_API_BATCH_SIZE + 1\n+    for batch in range(n_batches):\n         if loading_multiplier:\n             stream.send(\n-                f\"Fetching embeddings, batch {i+1}/{len(batches)}\",\n+                f\"Fetching embeddings, batch {batch+1}/{n_batches}\",\n                 channel=\"loading\",\n-                progress=(100 / len(batches)) * loading_multiplier,\n+                progress=(100 / n_batches) * loading_multiplier,\n             )\n         start_time = default_timer()\n-        response = await task\n+        i_start, i_end = (\n+            batch * EMBEDDINGS_API_BATCH_SIZE,\n+            (batch + 1) * EMBEDDINGS_API_BATCH_SIZE,\n+        )\n+        _texts = embed_texts[i_start:i_end]\n+        _checksums = embed_checksums[i_start:i_end]\n+        _tokens = embed_tokens[i_start:i_end]\n+        response = await llm_api_handler.call_embedding_api(_texts, embedding_model)\n         cost_tracker.log_api_call_stats(\n-            sum(items_to_embed_tokens[k] for k in batch),\n+            sum(_tokens),\n             0,\n@@ -186,3 +158,3 @@ async def get_feature_similarity_scores(\n         )\n-        database.set({k: v for k, v in zip(batch, response)})\n+        database.set({k: v for k, v in zip(_checksums, response)})\n \ndiff --git a/tests/embeddings_test.py b/tests/embeddings_test.py\nindex 1f241b8..f338599 100644\n--- a/tests/embeddings_test.py\n+++ b/tests/embeddings_test.py\n@@ -5,11 +5,3 @@ import pytest\n from mentat.code_feature import CodeFeature\n-from mentat.embeddings import _batch_ffd, get_feature_similarity_scores\n-\n-\n-def test_batch_ffd():\n-    data = {\"a\": 4, \"b\": 5, \"c\": 3, \"d\": 2}\n-    batch_size = 6\n-    result = _batch_ffd(data, batch_size)\n-    expected = [[\"b\"], [\"a\", \"d\"], [\"c\"]]\n-    assert result == expected\n+from mentat.embeddings import get_feature_similarity_scores\n \n",
    "message_history": [],
    "message_prompt": "Why was test_batch_ffd removed?",
    "message_edit": "The `test_batch_ffd` function was removed because the `_batch_ffd` function it was testing has been deleted from the `mentat/embeddings.py` file. The `_batch_ffd` function was responsible for batching files using the First Fit Decreasing algorithm, but it seems that the logic for batching has been changed or refactored, and this specific function is no longer part of the codebase. As a result, the corresponding test function is no longer necessary and has been removed as well.",
    "context": [
        "mentat/embeddings.py",
        "tests/embeddings_test.py"
    ],
    "diff_edit": "",
    "test_command": "",
    "version": "0.1.0"
}
