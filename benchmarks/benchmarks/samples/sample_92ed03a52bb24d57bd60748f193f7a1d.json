{
    "title": "Add variable to route",
    "description": "",
    "id": "92ed03a52bb24d57bd60748f193f7a1d",
    "parent_id": "40a0f175235e4331a05ecf1eade36a54",
    "repo": "http://github.com/granawkins/latent-dictionary",
    "merge_base": "d98e6db3e411ee2650048e72377e36feb42a5fce",
    "diff_merge_base": "",
    "diff_active": "diff --git a/backend/app.py b/backend/app.py\nindex 90dab63..9bc0a75 100644\n--- a/backend/app.py\n+++ b/backend/app.py\n@@ -1,9 +1,5 @@\n-import pickle\n-\n from flask import Flask, jsonify, request\n from flask_cors import CORS\n-import redis\n \n-from embeddings import DistilBertEmbeddingsModel\n-from pca import get_pca_for\n+from word_vectors import get_word_vectors\n \n@@ -12,55 +8,2 @@ CORS(app)\n \n-\n-# Load dependencies\n-model = DistilBertEmbeddingsModel()\n-with open('oxford_3000.txt') as f:\n-    oxford_3000 = [w.strip() for w in f.readlines()]\n-\n-\n-# A dict of all the different PCAs, indexed by word basis\n-pcas = {}\n-\n-# A database to store word embeddings\n-redis_client = redis.Redis(host='redis', port=6379, db=0)\n-\n-def get_word_vectors(\n-    highlight: list[str] = [], \n-    set_pca: bool = False, \n-    pca_id: str = \"default\"\n-):\n-    \"\"\"Return a dict of words and 3d vectors.\n-    \n-    Args:\n-        highlight: A list of items (besides oxford 3000) to embed\n-        set_pca: If true, apply new PCA based on highlight\n-        pca_id: To re-use a previous PCA\n-    \"\"\"\n-    global pcas\n-\n-    _highlight = [w for w in highlight if w.isalpha()]\n-    _oxford_3000 = [w for w in oxford_3000 if w.isalpha()]\n-    words = list(set(_highlight + _oxford_3000))\n-    new_words = [w for w in words if not redis_client.exists(w)]\n-    if new_words:\n-        new_embeddings = model.batch_get(new_words)\n-        for word, embedding in zip(new_words, new_embeddings):\n-            redis_client.set(word, pickle.dumps(embedding.tolist()))\n-    embeddings = [redis_client.get(w) for w in words]\n-    embeddings = [pickle.loads(e) if e else None for e in embeddings]\n-    index = {w: e for w, e in zip(words, embeddings) if e is not None}\n-\n-    if set_pca or (pca_id == \"default\" and \"default\" not in pcas):\n-        if set_pca:\n-            pca_id = str(str(_highlight.keys()))\n-            pca_vals = [index[w] for w in _highlight]\n-        else:\n-            pca_vals = [index[w] for w in _oxford_3000]\n-        pcas[pca_id] = get_pca_for(pca_vals)\n-    elif pca_id != \"default\" and pca_id not in pcas:\n-        raise ValueError(f\"Unrecognized pca_id: {pca_id}\")\n-\n-    vectors = pcas[pca_id].transform(embeddings)\n-    return {k: list(v) for k, v in zip(words, vectors)}\n-\n-\n _index_cache = None\ndiff --git a/backend/word_vectors.py b/backend/word_vectors.py\nnew file mode 100644\nindex 0000000..80d6ed5\n--- /dev/null\n+++ b/backend/word_vectors.py\n@@ -0,0 +1,54 @@\n+import pickle\n+import redis\n+\n+from embeddings import DistilBertEmbeddingsModel\n+from pca import get_pca_for\n+\n+model = DistilBertEmbeddingsModel()\n+with open('oxford_3000.txt') as f:\n+    oxford_3000 = [w.strip() for w in f.readlines()]\n+\n+# A dict of all the different PCAs, indexed by word basis\n+pcas = {}\n+\n+# A database to store word embeddings\n+redis_client = redis.Redis(host='redis', port=6379, db=0)\n+\n+def get_word_vectors(\n+    highlight: list[str] = [], \n+    set_pca: bool = False, \n+    pca_id: str = \"default\"\n+):\n+    \"\"\"Return a dict of words and 3d vectors.\n+    \n+    Args:\n+        highlight: A list of items (besides oxford 3000) to embed\n+        set_pca: If true, apply new PCA based on highlight\n+        pca_id: To re-use a previous PCA\n+    \"\"\"\n+    global pcas\n+\n+    _highlight = [w for w in highlight if w.isalpha()]\n+    _oxford_3000 = [w for w in oxford_3000 if w.isalpha()]\n+    words = list(set(_highlight + _oxford_3000))\n+    new_words = [w for w in words if not redis_client.exists(w)]\n+    if new_words:\n+        new_embeddings = model.batch_get(new_words)\n+        for word, embedding in zip(new_words, new_embeddings):\n+            redis_client.set(word, pickle.dumps(embedding.tolist()))\n+    embeddings = [redis_client.get(w) for w in words]\n+    embeddings = [pickle.loads(e) if e else None for e in embeddings]\n+    index = {w: e for w, e in zip(words, embeddings) if e is not None}\n+\n+    if set_pca or (pca_id == \"default\" and \"default\" not in pcas):\n+        if set_pca:\n+            pca_id = str(str(_highlight.keys()))\n+            pca_vals = [index[w] for w in _highlight]\n+        else:\n+            pca_vals = [index[w] for w in _oxford_3000]\n+        pcas[pca_id] = get_pca_for(pca_vals)\n+    elif pca_id != \"default\" and pca_id not in pcas:\n+        raise ValueError(f\"Unrecognized pca_id: {pca_id}\")\n+\n+    vectors = pcas[pca_id].transform(embeddings)\n+    return {k: list(v) for k, v in zip(words, vectors)}\n",
    "message_history": [
        {
            "role": "assistant",
            "content": "I will create a new file named `word_vectors.py` and move the `get_word_vectors` function along with its associated imports and helper variables to this new file. I will then import the `get_word_vectors` function in `app.py`.\n\nSteps:\n1. Create `word_vectors.py` with necessary imports, helper variables, and the `get_word_vectors` function.\n2. Remove the `get_word_vectors` function and associated helpers/imports from `app.py`.\n3. Import `get_word_vectors` from `word_vectors.py` in `app.py`."
        },
        {
            "role": "user",
            "content": "Move get_word_vectors and the associated helpers/imports to a new file called word_vectors.py, and just import get_word_vectors in app.py."
        }
    ],
    "message_prompt": "Update my get_vectors route to return a dict of {vectors, pca_id}. On the frontend, save the pca_id in a new useState variable.",
    "message_edit": "I will update the `get_vectors` route in `app.py` to return a dictionary containing both `vectors` and `pca_id`. On the frontend, I will add a new `useState` variable in `App.js` to store the `pca_id`.\n\nBackend Changes:\n1. Update the `get_vectors` route in `app.py` to return a dictionary with `vectors` and `pca_id`.\n\nFrontend Changes:\n2. Add a new `useState` variable in `App.js` to store the `pca_id`.\n3. Update the `fetchData` function in `App.js` to save the `pca_id` from the response.",
    "context": [
        "frontend/src/App.js",
        "backend/app.py"
    ],
    "diff_edit": "diff --git a/backend/app.py b/backend/app.py\nindex 9bc0a75..a5804d6 100644\n--- a/backend/app.py\n+++ b/backend/app.py\n@@ -21,3 +21,3 @@ def get_vectors():\n     vectors = get_word_vectors(highlight, set_pca, pca_id)\n-    return jsonify(vectors)\n+    return jsonify({\"vectors\": vectors, \"pca_id\": pca_id})\n \ndiff --git a/frontend/src/App.js b/frontend/src/App.js\nindex 8d9142e..f5be448 100644\n--- a/frontend/src/App.js\n+++ b/frontend/src/App.js\n@@ -12,2 +12,3 @@ const App = () => {\n     const [isLoading, setIsLoading] = useState(false)\n+    const [pcaId, setPcaId] = useState(null);\n \n@@ -27,4 +28,5 @@ const App = () => {\n             console.log(\"got data\", data)\n-            setCorpus(data);\n-            setSelected(Array(data.length).fill(false))\n+            setCorpus(data.vectors);\n+            setPcaId(data.pca_id);\n+            setSelected(Array(Object.keys(data.vectors).length).fill(false));\n         } finally {\n",
    "test_command": "",
    "version": "0.1.0"
}